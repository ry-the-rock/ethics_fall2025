---
title: 'Blog Post 8'
date: 2025-10-30
permalink: /posts/2025/10/blog-post-8/
tags:
  - bias
  - machine learning
  - harm
---

Reacting to a case study detailing the possible sources of bias within the machine learning process.

**Case Study Reading:** [Understanding Potential Sources of Harm throughout the Machine Learning Life Cycle](https://mit-serc.pubpub.org/pub/potential-sources-of-harm-throughout-the-machine-learning-life-cycle/release/2)

The Discussion
---
**Part 1: Case Study Summary**  
This case study details the machine learning process, then accentuates seven possible points where bias can enter and exist within the model. These sources are defined as historical, representation, measurement, learning, evaluation, and aggregation biases. 

**Part 2: Going Deeper**  
I thought this case study was very insightful in that it relinked the idea of data to the processes that created it. Thinking of data as a result of a cause and effect scenario was a new concept for me, but it logically makes sense.  

I also thought it was especially interesting that their definition for data was defined as a “product of a complex human-driven process,” with the emphasis (for me) on “human driven.” I think a lot of people outside of the computer science world don’t realize that, even with AI, there is a necessary human component to technology. For example, when I talk to my family about my major, they say that AI will take over everything and replace human effort. While I think AI is definitely stressing the computer science job market, I think that this perspective fails to recognize that artificial intelligence is not an independent entity; that is to say, it requires human input to function.  

Another thing I found interesting was the idea of mitigation versus eradication. Throughout this article, it continuously references this idea of mitigation. How can we lessen the possibility of harm; how can we mitigate bias? But it never once proposes the concept of eradication- the complete removal of harm, of bias. That’s because AI is not capable of such a feat. Complete eradication of harm or of bias is not possible with artificial intelligence.  

Weirdly enough, this made me think of the half life of radioactive entities. A table representing half life is shown below.

| Number of Half-Lives Elapsed  | Fraction Remaining  | Percent Remaining |
|------------------------------ |---------------------|-------------------|
| 0                             | \\(\frac{1}{1}\\)   | 100%              |
| 1                             | \\(\frac{1}{2}\\)   | 50%               |
| 2                             | \\(\frac{1}{4}\\)   | 25%               |
| 3                             | \\(\frac{1}{8}\\)   | 12.5%             |
| 4                             | \\(\frac{1}{16}\\)  | 6.25%             |
| 5                             | \\(\frac{1}{32}\\)  | 3.125%            |
| 6                             | \\(\frac{1}{64}\\)  | 1	.5625%          |
| 7                             | \\(\frac{1}{128}\\)    | 0	.78125%         |
| \\(n\\)                       | \\(\frac{1}{2^n}\\) | \\(\frac{100}{2^n}\\)% |

Taking half life out of a probability context, we can see that the equation will never fully reach 0; it can only approach it. Is this the best hope we can have for technology? Approaching no harm, but never fully removing it?  

**Part 3: Going Beyond**  
So, after that very optimistic rant, I want to ask this question: what do you think should be the purpose of AI? Of technology? Does this differ from what you perceive to be the current motivations of technological advancement? If so, how?  

**Part 4: Reflection**  
I thought this was a very beneficial case study. It broke the targeted topics down into understandable chunks and contributed, what I think to be, a good perspective on the possible sources of harm. While I don’t think the article itself was negative, discovering the holes in the language used has filled me with a sense of dread. I don't like the idea of harm and bias being a given. AI is advancing, but at what cost? And will it ever be enough?
