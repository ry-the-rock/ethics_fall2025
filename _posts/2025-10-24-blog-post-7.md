---
title: 'Blog Post 7'
date: 2025-10-24
permalink: /posts/2025/10/blog-post-7/
tags:
  - South Asia
  - stereotypes
  - text-to-image (T2I)
---

Engaging with a case study about cultural representation in AI.

**Case Study Reading:**
[AI’s Regimes of Representation: A Community-Centered Study of Text-to-Image Models in South Asia](https://mit-serc.pubpub.org/pub/bfw5tscj/release/3?readingCollection=65a1a268)

The Discussion
---
**Part 1: Case Study Summary**  
This case study circles around the idea of cultural representation in text-to-image AI models by accounting for non-Western perspectives, specifically those of South Asians. Using qualitiative data, the study attributes three key points of failure, mainly pertaining to stereotypes and inaccurate cultural depictions.

**Part 2: Going Deeper**  
When I picture cultural identity, I most greatly associate it with time and tradition. Practices and values are passed down from generation to generation, keeping core values alive. That being said, I would not say that I grew up in any type of culturally rich environment- I was a white American kid who lived out her childhood in suburban Utah. In my opinion, I didn’t (and still don’t) have much of a culture because I feel my experiences lack strength, definition, and connection when compared to others; they are not a point of distinguishment for me.  
And that is where representation’s importance comes in. I feel that the most poignant parts of someone’s identity, whether it be cultural or personal, stem from their deviation from the established norm of globalised Western European ideals. When this deviation occurs, these aspects can become a source of ridicule and blatant misrepresentation, simply because they are different from what most others accept. The outcome? Lots of popular media portraying harmful generalizations or attempting culture-nullifying assimilations, with very few accurate representations. This media is then used in generative AI models, and there are not enough “correct” representations to overwhelm the negative due to the high demand for data. Thus, we end up with examples as shown in the case study.  
In terms of mitigating this result, I do think more human effort is needed. Serious time should be dedicated to validating sources of cultural information, and smaller scale qualitative evaluations should happen often. However, I question the need for AI-generated content in the space of cultural representation. One huge solution to AI’s problem would be to have more sources of positive cultural depictions to feed the model. But then, since these accurate representations now already exist, what additional benefits does AI bring? To me, it feels conflicting to have such an important human aspect of life be depicted by a machine.  

**Part 3: Going Beyond**  
After reading this case study, I was left wondering if this problem of cultural inaccessibility is prevalent not only in T2I AI. Try and test a chatbot by prompting it about cultural ideas- is it able to distinguish between identities correctly? What about previous versions of the chatbot?  

**Part 4: Reflection**  
I never really thought about the cultural ramifications of T2I AI and how skewed its outputs could be. I've been hearing a lot about the Dead Internet Theory recently, especially with the huge boom in generated content, and its possible implications make me nervous for the future of cultural representations. Could these distortions just be fed back in to model, thus creating more cultural distortions? 