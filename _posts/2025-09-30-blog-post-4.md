---
title: 'Blog Post 4 - Algorithms 2 (Awaiting Grading)'
date: 2025-09-30
permalink: /posts/2025/09/blog-post-4/
tags:
  - case study
  - generative ai
  - deep learning
---

Responding to a case study pertaining to the history and limits of generative artificial intelligence.

**Case Study Reading:** [How Generative AI Works and How It Fails](https://mit-serc.pubpub.org/pub/f3o5mpn6/release/1?readingCollection=3a6c54f1)

The Discussion
---
**Part 1: Case Study Summary**  
This case study details the general history of generative AI while describing how it works. Then, it delves into its framework and user-based consequences. 

**Part 2: [Voice Deepfake](https://drive.google.com/file/d/1mrlb1QEGQWTDnH4SGxJisHcdn6PL8AqR/view?usp=drive_link)**  
I have never used any deepfake technology before, so this was very offputting. My roommate said it sort of sounded like me, and I agree. There are certain parts where I'm like "yeah, no," but at other times it was semi-convincing. Hearing what sounds like my voice (sort of) say words I have never said before is scary! And I know there are more advanced tools out there, most likely with subscriptions and paywalls (I was actually able to avoid the paywall by screen-recording the preview of the audio-- so yeah, I'm a woman in STEM), so that means there are more convincing versions of this tool that exist. Even attempting to use these programs was a bit dystopian. I had to search around for a bit until I found a website that I could use for free, so I got to interact with a couple of deepfake interfaces. A lot of them asked if they could keep my voice to use it as training data, and some even explicitly had this as a requirement! This made me… paranoid is maybe the best word? My voice or my likeness make up a large part of my interactive identity, so the fact that someone could fake something so personally related to my being is so unsettling. I am very worried about the power deepfake technology could possibly wield.  

**Part 3: Going Beyond**  
The case study focuses on the explicitly malicious results of generative AI, such as nonconsentual ponorgraphic deepfakes or just simply wrong information. Therefore, I would like to pose a more ambigious question. Do you believe the use of AI carries an ethical and humane weight? 

Now, I can think of an answer to this question in two ways. The first can be explained by considering the uses of generative AI. While not all uses of generative AI are bad (can be a conversational education tool, can help with drug discovery and medicinal development, etc.), its application into everyday life has exponentially increased what I believe to be lazy or unjust behaviors. Having an AI write a simple email to your coworkers, cheating on an essay, relying on chatbots for friends, generating AI 'art'. All of these behaviors, in my opinion, take us further away from what it means to be human.

The second way considers the impact. We know that AI is computationally expensive. Therefore, it must be expensive to maintain the infrastructure needed to complete such computations. Large AI companies are building warehouses in less developed countries while exploiting the residents for cheap labor and harming the local enironment.

I would like to follow up with one final question: At what point do you disregard that AI's ethical and humane weight?

**Part 4: Reflection**  
Voices are powerful. So what can you do when you can’t tell whether a voice is real or fake? I feel that generative AI, especially in the world of chatbots and deepfakes, can be so dangerous. I feel that, at one point, the AI bubble is going to pop. And who could we trust then?
