---
title: 'Blog Post 4'
date: 2025-09-30
permalink: /posts/2025/09/blog-post-4/
tags:
  - case study
  - generative ai
  - deep learning
---

Responding to a case study pertaining to the history and limits of generative artificial intelligence.

**Case Study Reading:** [How Generative AI Works and How It Fails](https://mit-serc.pubpub.org/pub/f3o5mpn6/release/1?readingCollection=3a6c54f1)

The Discussion
---
**Part 1: Case Study Summary**  
This case study details the general history of generative AI while describing how it works. Then, it delves into its framework and user-based consequences. 

**Part 2: [Voice Deepfake](https://drive.google.com/file/d/1mrlb1QEGQWTDnH4SGxJisHcdn6PL8AqR/view?usp=drive_link)**  
I have never used any deepfake technology before, so this was very offputting. My roommate said it sort of sounded like me, and I agree. There are certain parts where I'm like "yeah, no," but at other times it was semi-convincing. Hearing what sounds like my voice (sort of) say words I have never said before is scary! And I know there are more advanced tool out there, most likely with subscriptions and paywalls (I was actually able to avoid the paywall by screen-recording the preview of the audio-- so yeah, I'm a woman in STEM), so that means there are more convincing versions of this tool that exist.

**Part 3: Going Beyond**  
The case study focuses on the explicitly malicious results of generative AI, such as nonconsentual ponorgraphic deepfakes or just simply wrong information. Therefore, I would like to pose a more ambigious question. Do you believe the use of AI carries an ethical and humane weight? 

Now, I can think of an answer to this question in two ways. The first can be explained by considering the uses of generative AI. While not all uses of generative AI are bad (can be a conversational education tool, can help with drug discovery and medicinal development, etc.), its application into everyday life has exponentially increased what I believe to be lazy or unjust behaviors. Having an AI write a simple email to your coworkers, cheating on an essay, relying on chatbots for friends, generating AI 'art'. All of these behaviors, in my opinion, take us further away from what it means to be human.

The second way considers the impact. We know that AI is computationally expensive. Therefore, it must be expensive to maintain the infrastructure needed to complete such computations. Large AI companies are building warehouses in less developed countries while exploiting the residents for cheap labor and harming the local enironment.

I would like to follow up with one final question: At what point do you disregard that AI's ethical and humane weight?

**Part 4: Reflection**  
I feel really confident about this post! I tried to format it more as a general blog rather than an assignment. I had a lot to say and it took me while to whittle it all down.
